{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN implementation of even number generation from random noise ",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4oGKD9vNbLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f59Qule2JKu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,input_length:int):\n",
        "    super(Generator,self).__init__()\n",
        "    self.dense_layer=nn.Linear(int(input_length),int(input_length))\n",
        "    self.activation=nn.Sigmoid()\n",
        "  def forward(self,x):\n",
        "    return self.activation(self.dense_layer(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsxKATpjLdjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,input_length:int):\n",
        "    super(Discriminator,self).__init__()\n",
        "    self.dense_layer=nn.Linear(int(input_length),1)\n",
        "    self.activation=nn.Sigmoid()\n",
        "  def forward(self,x):\n",
        "    return self.activation(self.dense_layer(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXnNwhrZOgB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List\n",
        "\n",
        "def create_binary_list_from_int(number: int) -> List[int]:\n",
        "    return [int(x) for x in list(bin(number))[2:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeFaBQDXZtiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML8wscqZO1_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_even_data(max_int: int, batch_size: int=16)->([List[int], List[List[int]]]):\n",
        "    # Get the number of binary places needed to represent the maximum number\n",
        "    max_length = int(math.log(max_int, 2))\n",
        "\n",
        "    # Sample batch_size number of integers in range 0-max_int\n",
        "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
        "\n",
        "    # create a list of labels all ones because all numbers are even\n",
        "    labels = [1] * batch_size\n",
        "\n",
        "    # Generate a list of binary numbers for training.\n",
        "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
        "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
        "    data=np.array(data)\n",
        "    labels=np.array(labels)\n",
        "    return labels, data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6DF-U-geI18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 500):\n",
        "    input_length = int(math.log(max_int, 2))\n",
        "\n",
        "    # Models\n",
        "    generator = Generator(input_length)\n",
        "    discriminator = Discriminator(input_length)\n",
        "\n",
        "    # Optimizers\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "    # loss\n",
        "    loss = nn.BCELoss()\n",
        "\n",
        "    for i in range(training_steps):\n",
        "        # zero the gradients on each iteration\n",
        "        generator_optimizer.zero_grad()\n",
        "\n",
        "        # Create noisy input for generator\n",
        "        # Need float type instead of int\n",
        "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
        "        random_noise=torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
        "        generated_data = generator(noise)\n",
        "        generated_data1= generator(noise)\n",
        "        \n",
        "        if i%50==0:\n",
        "          generated_data1=generated_data1.detach().numpy()\n",
        "          generated_data1=(generated_data1>=0.5)*1\n",
        "          x,y=generated_data1.shape\n",
        "          generated_output=[]\n",
        "          noise1=[]\n",
        "          for j in range(x):\n",
        "            sum=0\n",
        "            for k in range(y):\n",
        "              sum=sum+pow(2,y-1-k)*generated_data1[j][k]\n",
        "            generated_output.append(sum)\n",
        "          random_noise=random_noise.detach().numpy()\n",
        "          #random_noise=(random>=0.5)*1\n",
        "          u,v=random_noise.shape\n",
        "          for j in range(u):\n",
        "            sum=0\n",
        "            for k in range(v):\n",
        "              sum=sum+pow(2,v-1-k)*random_noise[j][k]\n",
        "            noise1.append(sum)\n",
        "          print(f'generated_output:{generated_output}')\n",
        "          print(f'input:{noise1}')\n",
        "        # Generate examples of even real data\n",
        "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
        "        true_labels = torch.tensor(true_labels).float()\n",
        "        true_data = torch.tensor(true_data).float()\n",
        "        #print(true_data.shape)\n",
        "        #print(true_labels.unsqueeze(1).shape)\n",
        "        # Train the generator\n",
        "        # We invert the labels here and don't train the discriminator because we want the generator\n",
        "        # to make things the discriminator classifies as true.\n",
        "        generator_discriminator_out = discriminator(generated_data)\n",
        "        #print(generator_discriminator_out.shape)\n",
        "        generator_loss = loss(generator_discriminator_out, true_labels.unsqueeze(1))\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        # Train the discriminator on the true/generated data\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        true_discriminator_out = discriminator(true_data)\n",
        "        true_discriminator_loss = loss(true_discriminator_out, true_labels.unsqueeze(1))\n",
        "\n",
        "        # add .detach() here think about this\n",
        "        generator_discriminator_out = discriminator(generated_data.detach())\n",
        "        generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size,1))\n",
        "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVDCMp6zgO2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "749a0c96-89ac-4ffb-c593-28b9da7e7d67"
      },
      "source": [
        "train(max_int= 2048, batch_size= 16, training_steps = 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generated_output:[808, 812, 873, 521, 1768, 1864, 617, 1801, 777, 333, 1837, 812, 808, 77, 589, 873]\n",
            "input:[1425.0, 1355.0, 786.0, 1379.0, 275.0, 34.0, 2025.0, 1160.0, 1022.0, 1836.0, 840.0, 1529.0, 2046.0, 960.0, 76.0, 14.0]\n",
            "generated_output:[940, 1421, 365, 1965, 1325, 1325, 1293, 941, 301, 1964, 813, 1929, 269, 1965, 1325, 1325]\n",
            "input:[1615.0, 165.0, 525.0, 414.0, 911.0, 1834.0, 1972.0, 549.0, 92.0, 1423.0, 302.0, 295.0, 1962.0, 1762.0, 669.0, 1392.0]\n",
            "generated_output:[1293, 269, 1421, 1453, 301, 300, 1421, 1325, 269, 1325, 1421, 1325, 1453, 301, 1453, 1421]\n",
            "input:[1559.0, 1998.0, 741.0, 998.0, 2002.0, 1016.0, 1921.0, 56.0, 457.0, 1865.0, 980.0, 1702.0, 665.0, 1878.0, 533.0, 1321.0]\n",
            "generated_output:[1420, 1420, 1452, 1420, 1293, 300, 1165, 1420, 1293, 1421, 268, 1420, 268, 1420, 1420, 1420]\n",
            "input:[706.0, 1067.0, 549.0, 1450.0, 760.0, 1239.0, 243.0, 1710.0, 1237.0, 1555.0, 1415.0, 1215.0, 1480.0, 1005.0, 1561.0, 78.0]\n",
            "generated_output:[1420, 1420, 396, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 396, 1420, 1420, 1452, 1420, 1420]\n",
            "input:[1170.0, 1851.0, 1014.0, 432.0, 1218.0, 560.0, 1653.0, 2044.0, 215.0, 2024.0, 757.0, 199.0, 1103.0, 1663.0, 112.0, 1423.0]\n",
            "generated_output:[1420, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 1420, 396, 1420, 1420, 1420]\n",
            "input:[1191.0, 90.0, 1147.0, 678.0, 257.0, 1129.0, 1875.0, 1301.0, 10.0, 74.0, 342.0, 1064.0, 1295.0, 1401.0, 413.0, 1180.0]\n",
            "generated_output:[1420, 1420, 1444, 1420, 1452, 1446, 1452, 1444, 1420, 1452, 1444, 1420, 1412, 428, 1164, 1444]\n",
            "input:[1355.0, 236.0, 312.0, 227.0, 1505.0, 1649.0, 185.0, 1962.0, 778.0, 633.0, 1659.0, 56.0, 501.0, 1794.0, 506.0, 1965.0]\n",
            "generated_output:[1446, 1446, 428, 1444, 1252, 1444, 1510, 1252, 1446, 1446, 1190, 1316, 1446, 1446, 1508, 1190]\n",
            "input:[1751.0, 489.0, 326.0, 434.0, 1680.0, 767.0, 1530.0, 75.0, 226.0, 1660.0, 1407.0, 1992.0, 1371.0, 950.0, 1280.0, 1036.0]\n",
            "generated_output:[1254, 1254, 1254, 1254, 1254, 230, 1254, 1254, 1254, 1254, 230, 166, 1254, 422, 166, 1254]\n",
            "input:[1660.0, 597.0, 527.0, 103.0, 1880.0, 496.0, 1084.0, 615.0, 1332.0, 1036.0, 1088.0, 1721.0, 1160.0, 1088.0, 1981.0, 443.0]\n",
            "generated_output:[230, 230, 230, 1254, 1254, 230, 1254, 230, 230, 230, 230, 230, 1254, 230, 1254, 230]\n",
            "input:[618.0, 2016.0, 1155.0, 793.0, 353.0, 375.0, 477.0, 1508.0, 787.0, 916.0, 1434.0, 1943.0, 1203.0, 438.0, 595.0, 1356.0]\n",
            "generated_output:[102, 230, 210, 230, 246, 1270, 166, 198, 246, 194, 230, 230, 214, 246, 198, 246]\n",
            "input:[143.0, 1643.0, 788.0, 1194.0, 1511.0, 1503.0, 1714.0, 1107.0, 1533.0, 1026.0, 1181.0, 1060.0, 440.0, 516.0, 635.0, 1039.0]\n",
            "generated_output:[214, 210, 86, 82, 210, 210, 210, 210, 210, 242, 86, 210, 214, 210, 210, 246]\n",
            "input:[1688.0, 1861.0, 430.0, 538.0, 2023.0, 777.0, 1273.0, 356.0, 919.0, 531.0, 870.0, 1213.0, 1143.0, 686.0, 927.0, 681.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}